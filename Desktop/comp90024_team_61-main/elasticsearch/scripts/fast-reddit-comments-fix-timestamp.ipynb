{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3d6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Elasticsearch!\n",
      "Cluster name: elasticsearch\n",
      "Version: 8.5.1\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch,helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    verify_certs=False,\n",
    "    ssl_show_warn=False,\n",
    "    basic_auth=(\"elastic\", \"elastic\") \n",
    ")\n",
    "\n",
    "try:\n",
    "    info = es.info()\n",
    "    print(\"‚úÖ Connected to Elasticsearch!\")\n",
    "    print(f\"Cluster name: {info['cluster_name']}\")\n",
    "    print(f\"Version: {info['version']['number']}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb97912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84557f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'reddit_comments_scored_fixed'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_index = \"reddit_comments_scored\"\n",
    "reference_index = \"reddit_comments\"\n",
    "target_index = \"reddit_comments_scored_fixed\"\n",
    "\n",
    "es.indices.create(\n",
    "    index=target_index,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"id\": {\"type\": \"keyword\"},\n",
    "                \"type\": {\"type\": \"keyword\"},\n",
    "                \"platform\": {\"type\": \"keyword\"},\n",
    "                \"content\": {\"type\": \"text\"},\n",
    "                \"author\": {\"type\": \"keyword\"},\n",
    "                \"like\": {\"type\": \"integer\"},\n",
    "                \"post_id\": {\"type\": \"keyword\"},\n",
    "                \"created_utc\": {\"type\": \"date\", \"format\": \"epoch_second\"},\n",
    "                \"text_for_sentiment\": {\"type\": \"text\"},\n",
    "                \"bertweet_sentiment\": {\"type\": \"float\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9b80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total documents to process: 2922479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2922479/2922479 [03:15<00:00, 14944.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected 2922479 timestamps from reference index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reference_map = {}\n",
    "scroll = es.search(\n",
    "    index=\"reddit_comments\",\n",
    "    scroll=\"2m\",\n",
    "    size=1000,\n",
    "    body={\"_source\": [\"id\", \"created_utc\"], \"query\": {\"match_all\": {}}}\n",
    ")\n",
    "\n",
    "scroll_id = scroll[\"_scroll_id\"]\n",
    "docs = scroll[\"hits\"][\"hits\"]\n",
    "\n",
    "total = scroll[\"hits\"][\"total\"][\"value\"]\n",
    "print(f\"üîç Total documents to process: {total}\")\n",
    "\n",
    "pbar = tqdm(total=total)\n",
    "\n",
    "while docs:\n",
    "    for doc in docs:\n",
    "        doc_id = doc[\"_source\"][\"id\"]\n",
    "        created = doc[\"_source\"][\"created_utc\"]\n",
    "        reference_map[doc_id] = created\n",
    "        pbar.update(1)\n",
    "\n",
    "    scroll = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "    scroll_id = scroll[\"_scroll_id\"]\n",
    "    docs = scroll[\"hits\"][\"hits\"]\n",
    "\n",
    "pbar.close()\n",
    "print(f\"‚úÖ Collected {len(reference_map)} timestamps from reference index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad721e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reindexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2726394/2726394 [17:43<00:00, 2564.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Finished fast reindexing to corrected reddit_comments index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scroll = es.search(\n",
    "    index=source_index,\n",
    "    scroll=\"2m\",\n",
    "    size=1000,\n",
    "    body={\"query\": {\"match_all\": {}}}\n",
    ")\n",
    "scroll_id = scroll[\"_scroll_id\"]\n",
    "docs = scroll[\"hits\"][\"hits\"]\n",
    "total = scroll[\"hits\"][\"total\"][\"value\"]\n",
    "pbar = tqdm(total=total, desc=\"Reindexing\")\n",
    "\n",
    "actions = []\n",
    "\n",
    "\n",
    "while docs:\n",
    "    for doc in docs:\n",
    "        doc_id = doc[\"_source\"][\"id\"]\n",
    "        source = doc[\"_source\"]\n",
    "\n",
    "        if \"bertweet_sentiment\" not in source:\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        ref_created = reference_map.get(doc_id)\n",
    "        if isinstance(ref_created, int):\n",
    "            source[\"created_utc\"] = ref_created\n",
    "        else:\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        action = {\n",
    "            \"_index\": target_index,\n",
    "            \"_id\": doc_id,\n",
    "            \"_source\": source\n",
    "        }\n",
    "        actions.append(action)\n",
    "\n",
    "        if len(actions) >= 1000:\n",
    "            helpers.bulk(es, actions)\n",
    "            actions = []\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    scroll = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "    scroll_id = scroll[\"_scroll_id\"]\n",
    "    docs = scroll[\"hits\"][\"hits\"]\n",
    "\n",
    "if actions:\n",
    "    helpers.bulk(es, actions)\n",
    "\n",
    "pbar.close()\n",
    "print(\"üéâ Finished fast reindexing to corrected reddit_comments index.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
